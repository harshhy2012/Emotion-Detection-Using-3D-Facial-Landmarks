{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "7df332387c0946b9fa392827f6610f004e6a54f5679a7c41b4cedf79853f2c0c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'d:\\\\majorProjectV2\\\\Emotion_final_CK_plus_SPH_NORMAL_XXX.csv'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "path =  os.path.normpath(os.getcwd() + os.sep + os.pardir)\n",
    "path.replace('/','\\\\')\n",
    "path += '\\\\'\n",
    "\n",
    "file = ['Emotion_final_CK_plus_XYZ_NORMAL.csv',\n",
    "        'Emotion_final_CK_plus_XXX_NORMAL.csv',\n",
    "        'Emotion_final_CK_plus_SPH_NORMAL.csv',\n",
    "        'Emotion_final_CK_plus_SPH_NORMAL_XXX.csv',\n",
    "        'Emotion_final_CK_plus_ANGLE.csv']\n",
    "\n",
    "path = path+file[3]\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "905 -2.034349 -1.967114 -1.899879 -1.832644 -1.681366 -1.479661 -1.193913   \n",
       "906 -2.159580 -2.021998 -1.884416 -1.815625 -1.592055 -1.316891 -0.955739   \n",
       "907 -2.050473 -1.967792 -1.835504 -1.752823 -1.620535 -1.322886 -0.975628   \n",
       "908 -1.958494 -1.875685 -1.668662 -1.606556 -1.399533 -1.130404 -0.861275   \n",
       "909 -2.073102 -1.928533 -1.800027 -1.655458 -1.526952 -1.253877 -0.916549   \n",
       "910 -2.077533 -1.934653 -1.863213 -1.720334 -1.577454 -1.345275 -0.988076   \n",
       "911 -2.190289 -2.117883 -1.991172 -1.846360 -1.647242 -1.393820 -1.067992   \n",
       "912 -2.012280 -1.955319 -1.884118 -1.812916 -1.613552 -1.357226 -1.015459   \n",
       "913 -2.098813 -1.944522 -1.807374 -1.670227 -1.464505 -1.173066 -0.898771   \n",
       "914 -1.996789 -1.930587 -1.864384 -1.731979 -1.599573 -1.334763 -1.069952   \n",
       "915 -1.995737 -1.913468 -1.781839 -1.716024 -1.584394 -1.304682 -1.024969   \n",
       "916 -2.110353 -1.966705 -1.823058 -1.679410 -1.471919 -1.264428 -0.897328   \n",
       "917 -1.876404 -1.807915 -1.739426 -1.653814 -1.585325 -1.362735 -1.003166   \n",
       "918 -2.080020 -1.994670 -1.858111 -1.789831 -1.636202 -1.346013 -0.987545   \n",
       "919 -2.124222 -1.990457 -1.837583 -1.703818 -1.493616 -1.149649 -0.786572   \n",
       "\n",
       "            7         8         9  ...       195       196       197  \\\n",
       "905 -0.773695 -0.134964  0.419723  ...  0.703517  0.494348  0.776678   \n",
       "906 -0.525795  0.110521  0.678046  ...  0.346465  0.167882  0.450526   \n",
       "907 -0.545690  0.165361  0.744123  ...  0.011804 -0.221597  0.324078   \n",
       "908 -0.467932  0.070327  0.691394  ...  0.570012  0.323468  0.616915   \n",
       "909 -0.514968  0.095435  0.705837  ...  0.270981  0.052879  0.368842   \n",
       "910 -0.630877 -0.041498  0.619320  ...  0.382123  0.208641  0.512085   \n",
       "911 -0.597352  0.054305  0.579250  ...  0.511816  0.308317  0.583363   \n",
       "912 -0.545529  0.052563  0.650656  ...  0.578513  0.267378  0.660808   \n",
       "913 -0.470185  0.095550  0.729858  ...  0.413609  0.182830  0.568888   \n",
       "914 -0.606533 -0.010709  0.585115  ...  0.350280  0.091006  0.552377   \n",
       "915 -0.695895 -0.070654  0.472318  ...  0.470120  0.254756  0.628210   \n",
       "916 -0.482346  0.092244  0.650874  ...  0.351463  0.198290  0.490219   \n",
       "917 -0.712087 -0.129928  0.537842  ...  0.238365  0.090745  0.618760   \n",
       "918 -0.543727  0.036650  0.617027  ...  0.448489  0.228417  0.513663   \n",
       "919 -0.366168  0.188002  0.818608  ...  0.566348  0.343044  0.647074   \n",
       "\n",
       "          198       199       200       201       202       203  Emotion  \n",
       "905  0.811909  0.744794  0.382721  0.695267  0.728830  0.725439        6  \n",
       "906  0.479093  0.413487  0.026206  0.399207  0.437259  0.432697        6  \n",
       "907  0.395218  0.339848 -0.214400  0.195044  0.232680  0.177880        5  \n",
       "908  0.666029  0.631826  0.351692  0.682535  0.692044  0.665773        1  \n",
       "909  0.422489  0.386120  0.081395  0.414419  0.426535  0.395715        6  \n",
       "910  0.547354  0.487563  0.113137  0.463307  0.491546  0.486621        6  \n",
       "911  0.617412  0.559029  0.205502  0.553159  0.579914  0.578144        6  \n",
       "912  0.706114  0.634687  0.167185  0.632947  0.686335  0.660699        4  \n",
       "913  0.626926  0.573772  0.163553  0.507561  0.534331  0.501835        6  \n",
       "914  0.605558  0.533295  0.005935  0.453226  0.504380  0.470324        4  \n",
       "915  0.690610  0.645328  0.285208  0.573345  0.582231  0.553795        6  \n",
       "916  0.520596  0.452704  0.058856  0.407791  0.442415  0.439150        6  \n",
       "917  0.709722  0.655490  0.177438  0.400573  0.406473  0.359308        7  \n",
       "918  0.547080  0.489413  0.134909  0.500351  0.532553  0.521860        6  \n",
       "919  0.683835  0.617979  0.234511  0.594200  0.633643  0.621327        6  \n",
       "\n",
       "[15 rows x 205 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>195</th>\n      <th>196</th>\n      <th>197</th>\n      <th>198</th>\n      <th>199</th>\n      <th>200</th>\n      <th>201</th>\n      <th>202</th>\n      <th>203</th>\n      <th>Emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>905</th>\n      <td>-2.034349</td>\n      <td>-1.967114</td>\n      <td>-1.899879</td>\n      <td>-1.832644</td>\n      <td>-1.681366</td>\n      <td>-1.479661</td>\n      <td>-1.193913</td>\n      <td>-0.773695</td>\n      <td>-0.134964</td>\n      <td>0.419723</td>\n      <td>...</td>\n      <td>0.703517</td>\n      <td>0.494348</td>\n      <td>0.776678</td>\n      <td>0.811909</td>\n      <td>0.744794</td>\n      <td>0.382721</td>\n      <td>0.695267</td>\n      <td>0.728830</td>\n      <td>0.725439</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>906</th>\n      <td>-2.159580</td>\n      <td>-2.021998</td>\n      <td>-1.884416</td>\n      <td>-1.815625</td>\n      <td>-1.592055</td>\n      <td>-1.316891</td>\n      <td>-0.955739</td>\n      <td>-0.525795</td>\n      <td>0.110521</td>\n      <td>0.678046</td>\n      <td>...</td>\n      <td>0.346465</td>\n      <td>0.167882</td>\n      <td>0.450526</td>\n      <td>0.479093</td>\n      <td>0.413487</td>\n      <td>0.026206</td>\n      <td>0.399207</td>\n      <td>0.437259</td>\n      <td>0.432697</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>907</th>\n      <td>-2.050473</td>\n      <td>-1.967792</td>\n      <td>-1.835504</td>\n      <td>-1.752823</td>\n      <td>-1.620535</td>\n      <td>-1.322886</td>\n      <td>-0.975628</td>\n      <td>-0.545690</td>\n      <td>0.165361</td>\n      <td>0.744123</td>\n      <td>...</td>\n      <td>0.011804</td>\n      <td>-0.221597</td>\n      <td>0.324078</td>\n      <td>0.395218</td>\n      <td>0.339848</td>\n      <td>-0.214400</td>\n      <td>0.195044</td>\n      <td>0.232680</td>\n      <td>0.177880</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>908</th>\n      <td>-1.958494</td>\n      <td>-1.875685</td>\n      <td>-1.668662</td>\n      <td>-1.606556</td>\n      <td>-1.399533</td>\n      <td>-1.130404</td>\n      <td>-0.861275</td>\n      <td>-0.467932</td>\n      <td>0.070327</td>\n      <td>0.691394</td>\n      <td>...</td>\n      <td>0.570012</td>\n      <td>0.323468</td>\n      <td>0.616915</td>\n      <td>0.666029</td>\n      <td>0.631826</td>\n      <td>0.351692</td>\n      <td>0.682535</td>\n      <td>0.692044</td>\n      <td>0.665773</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>909</th>\n      <td>-2.073102</td>\n      <td>-1.928533</td>\n      <td>-1.800027</td>\n      <td>-1.655458</td>\n      <td>-1.526952</td>\n      <td>-1.253877</td>\n      <td>-0.916549</td>\n      <td>-0.514968</td>\n      <td>0.095435</td>\n      <td>0.705837</td>\n      <td>...</td>\n      <td>0.270981</td>\n      <td>0.052879</td>\n      <td>0.368842</td>\n      <td>0.422489</td>\n      <td>0.386120</td>\n      <td>0.081395</td>\n      <td>0.414419</td>\n      <td>0.426535</td>\n      <td>0.395715</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>910</th>\n      <td>-2.077533</td>\n      <td>-1.934653</td>\n      <td>-1.863213</td>\n      <td>-1.720334</td>\n      <td>-1.577454</td>\n      <td>-1.345275</td>\n      <td>-0.988076</td>\n      <td>-0.630877</td>\n      <td>-0.041498</td>\n      <td>0.619320</td>\n      <td>...</td>\n      <td>0.382123</td>\n      <td>0.208641</td>\n      <td>0.512085</td>\n      <td>0.547354</td>\n      <td>0.487563</td>\n      <td>0.113137</td>\n      <td>0.463307</td>\n      <td>0.491546</td>\n      <td>0.486621</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>911</th>\n      <td>-2.190289</td>\n      <td>-2.117883</td>\n      <td>-1.991172</td>\n      <td>-1.846360</td>\n      <td>-1.647242</td>\n      <td>-1.393820</td>\n      <td>-1.067992</td>\n      <td>-0.597352</td>\n      <td>0.054305</td>\n      <td>0.579250</td>\n      <td>...</td>\n      <td>0.511816</td>\n      <td>0.308317</td>\n      <td>0.583363</td>\n      <td>0.617412</td>\n      <td>0.559029</td>\n      <td>0.205502</td>\n      <td>0.553159</td>\n      <td>0.579914</td>\n      <td>0.578144</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>912</th>\n      <td>-2.012280</td>\n      <td>-1.955319</td>\n      <td>-1.884118</td>\n      <td>-1.812916</td>\n      <td>-1.613552</td>\n      <td>-1.357226</td>\n      <td>-1.015459</td>\n      <td>-0.545529</td>\n      <td>0.052563</td>\n      <td>0.650656</td>\n      <td>...</td>\n      <td>0.578513</td>\n      <td>0.267378</td>\n      <td>0.660808</td>\n      <td>0.706114</td>\n      <td>0.634687</td>\n      <td>0.167185</td>\n      <td>0.632947</td>\n      <td>0.686335</td>\n      <td>0.660699</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>913</th>\n      <td>-2.098813</td>\n      <td>-1.944522</td>\n      <td>-1.807374</td>\n      <td>-1.670227</td>\n      <td>-1.464505</td>\n      <td>-1.173066</td>\n      <td>-0.898771</td>\n      <td>-0.470185</td>\n      <td>0.095550</td>\n      <td>0.729858</td>\n      <td>...</td>\n      <td>0.413609</td>\n      <td>0.182830</td>\n      <td>0.568888</td>\n      <td>0.626926</td>\n      <td>0.573772</td>\n      <td>0.163553</td>\n      <td>0.507561</td>\n      <td>0.534331</td>\n      <td>0.501835</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>914</th>\n      <td>-1.996789</td>\n      <td>-1.930587</td>\n      <td>-1.864384</td>\n      <td>-1.731979</td>\n      <td>-1.599573</td>\n      <td>-1.334763</td>\n      <td>-1.069952</td>\n      <td>-0.606533</td>\n      <td>-0.010709</td>\n      <td>0.585115</td>\n      <td>...</td>\n      <td>0.350280</td>\n      <td>0.091006</td>\n      <td>0.552377</td>\n      <td>0.605558</td>\n      <td>0.533295</td>\n      <td>0.005935</td>\n      <td>0.453226</td>\n      <td>0.504380</td>\n      <td>0.470324</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>915</th>\n      <td>-1.995737</td>\n      <td>-1.913468</td>\n      <td>-1.781839</td>\n      <td>-1.716024</td>\n      <td>-1.584394</td>\n      <td>-1.304682</td>\n      <td>-1.024969</td>\n      <td>-0.695895</td>\n      <td>-0.070654</td>\n      <td>0.472318</td>\n      <td>...</td>\n      <td>0.470120</td>\n      <td>0.254756</td>\n      <td>0.628210</td>\n      <td>0.690610</td>\n      <td>0.645328</td>\n      <td>0.285208</td>\n      <td>0.573345</td>\n      <td>0.582231</td>\n      <td>0.553795</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>916</th>\n      <td>-2.110353</td>\n      <td>-1.966705</td>\n      <td>-1.823058</td>\n      <td>-1.679410</td>\n      <td>-1.471919</td>\n      <td>-1.264428</td>\n      <td>-0.897328</td>\n      <td>-0.482346</td>\n      <td>0.092244</td>\n      <td>0.650874</td>\n      <td>...</td>\n      <td>0.351463</td>\n      <td>0.198290</td>\n      <td>0.490219</td>\n      <td>0.520596</td>\n      <td>0.452704</td>\n      <td>0.058856</td>\n      <td>0.407791</td>\n      <td>0.442415</td>\n      <td>0.439150</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>917</th>\n      <td>-1.876404</td>\n      <td>-1.807915</td>\n      <td>-1.739426</td>\n      <td>-1.653814</td>\n      <td>-1.585325</td>\n      <td>-1.362735</td>\n      <td>-1.003166</td>\n      <td>-0.712087</td>\n      <td>-0.129928</td>\n      <td>0.537842</td>\n      <td>...</td>\n      <td>0.238365</td>\n      <td>0.090745</td>\n      <td>0.618760</td>\n      <td>0.709722</td>\n      <td>0.655490</td>\n      <td>0.177438</td>\n      <td>0.400573</td>\n      <td>0.406473</td>\n      <td>0.359308</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>918</th>\n      <td>-2.080020</td>\n      <td>-1.994670</td>\n      <td>-1.858111</td>\n      <td>-1.789831</td>\n      <td>-1.636202</td>\n      <td>-1.346013</td>\n      <td>-0.987545</td>\n      <td>-0.543727</td>\n      <td>0.036650</td>\n      <td>0.617027</td>\n      <td>...</td>\n      <td>0.448489</td>\n      <td>0.228417</td>\n      <td>0.513663</td>\n      <td>0.547080</td>\n      <td>0.489413</td>\n      <td>0.134909</td>\n      <td>0.500351</td>\n      <td>0.532553</td>\n      <td>0.521860</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>919</th>\n      <td>-2.124222</td>\n      <td>-1.990457</td>\n      <td>-1.837583</td>\n      <td>-1.703818</td>\n      <td>-1.493616</td>\n      <td>-1.149649</td>\n      <td>-0.786572</td>\n      <td>-0.366168</td>\n      <td>0.188002</td>\n      <td>0.818608</td>\n      <td>...</td>\n      <td>0.566348</td>\n      <td>0.343044</td>\n      <td>0.647074</td>\n      <td>0.683835</td>\n      <td>0.617979</td>\n      <td>0.234511</td>\n      <td>0.594200</td>\n      <td>0.633643</td>\n      <td>0.621327</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>15 rows × 205 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df = pd.read_csv(path)\n",
    "df = df.drop(['Image_name'], axis = 1)\n",
    "df = df.drop(['Unnamed: 0'], axis = 1)\n",
    "for i in range(1,10):\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Emotion', axis=1)\n",
    "y = df.Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.4855072463768116\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB().fit(X_train, y_train) \n",
    "gnb_predictions = gnb.predict(X_test) \n",
    "  \n",
    "# accuracy on X_test \n",
    "accuracy = gnb.score(X_test, y_test) \n",
    "print(accuracy) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, gnb_predictions) "
   ]
  }
 ]
}